{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from tensorflow.keras.activations import  relu, hard_sigmoid\n",
    "from tensorflow.keras.layers import  Conv2D, ConvLSTM2D, Conv2DTranspose\n",
    "from tensorflow.keras.layers import BatchNormalization , Concatenate\n",
    "from keras import Model\n",
    "import numpy as np\n",
    "import os\n",
    "from IPython.display import Image, display\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from PIL import ImageOps\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = \"/home/roz/workspace/depth net/dataset/depth_selection/val_selection_cropped/image\"\n",
    "target_dir = \"/home/roz/workspace/depth net/dataset/depth_selection/val_selection_cropped/groundtruth_depth\"\n",
    "\n",
    "height= 256\n",
    "width = 256\n",
    "img_size = (height, width)\n",
    "batch_size = 5\n",
    "time_step= 3\n",
    "\n",
    "input_img_paths = sorted(\n",
    "    [\n",
    "        os.path.join(input_dir, fname)\n",
    "        for fname in os.listdir(input_dir)\n",
    "        if fname.endswith(\".png\")\n",
    "    ]\n",
    ")\n",
    "target_img_paths = sorted(\n",
    "    [\n",
    "        os.path.join(target_dir, fname)\n",
    "        for fname in os.listdir(target_dir)\n",
    "        if fname.endswith(\".png\") and not fname.startswith(\".\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"Number of samples:\", len(input_img_paths))\n",
    "\n",
    "for input_path, target_path in zip(input_img_paths[:10], target_img_paths[:10]):\n",
    "    print(input_path, \"|\", target_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input_dir = \"/home/roz/workspace/depth net/dataset/depth_selection/val_selection_cropped/image_test\"\n",
    "test_target_dir = \"/home/roz/workspace/depth net/dataset/depth_selection/val_selection_cropped/groundtruth_depth_test\"\n",
    "\n",
    "height= 256\n",
    "width = 256\n",
    "img_size = (height, width)\n",
    "batch_size = 5\n",
    "time_step= 3\n",
    "\n",
    "test_input_img_paths = sorted(\n",
    "    [\n",
    "        os.path.join(test_input_dir, fname)\n",
    "        for fname in os.listdir(test_input_dir)\n",
    "        if fname.endswith(\".png\")\n",
    "    ]\n",
    ")\n",
    "test_target_img_paths = sorted(\n",
    "    [\n",
    "        os.path.join(test_target_dir, fname)\n",
    "        for fname in os.listdir(test_target_dir)\n",
    "        if fname.endswith(\".png\") and not fname.startswith(\".\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"Number of samples:\", len(test_input_img_paths))\n",
    "\n",
    "for test_input_path, test_target_path in zip(test_input_img_paths[:10], test_target_img_paths[:10]):\n",
    "    print(test_input_path, \"|\", test_target_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import PIL.Image\n",
    "# Display input image #7\n",
    "display(Image(filename=input_img_paths[7]))\n",
    "\n",
    "# Display auto-contrast version of corresponding target (per-pixel categories)\n",
    "that = ImageOps.autocontrast(load_img(target_img_paths[7]))\n",
    "display(that)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import PIL.Image\n",
    "# Display input image #7\n",
    "display(Image(filename=test_input_img_paths[7]))\n",
    "\n",
    "# Display auto-contrast version of corresponding target (per-pixel categories)\n",
    "that = ImageOps.autocontrast(load_img(test_target_img_paths[7]))\n",
    "display(that)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare(batch_size, time_step ,img_size, input_img_paths, target_img_paths):\n",
    "        for idx in range(len(input_img_paths)):\n",
    "            i = idx * batch_size\n",
    "            batch_input_img_paths = input_img_paths[i : i + batch_size]\n",
    "            batch_target_img_paths = target_img_paths[i : i + batch_size]\n",
    "            x = np.zeros((batch_size,)+ (time_step,) + img_size + (3,) )#dtype=\"float32\")\n",
    "            for j, path in enumerate(batch_input_img_paths):\n",
    "                img = load_img(path, target_size=img_size)\n",
    "                x[j] = img\n",
    "            y = np.zeros((batch_size,)+(time_step,) + img_size + (1,) )#dtype=\"float32\")\n",
    "            for j, path in enumerate(batch_target_img_paths):\n",
    "                img = load_img(path, target_size=img_size, color_mode=\"grayscale\")\n",
    "                y[j] = np.expand_dims(img, 2)\n",
    "                #print(y.shape)\n",
    "                #print (y)\n",
    "                # Ground truth labels are 1, 2, 3. Subtract one to make them 0, 1, 2:\n",
    "                #y[j] -= 1\n",
    "        #print(f'x: {x}')  \n",
    "        #print(f'y: {y}')     \n",
    "        return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y= prepare( batch_size,time_step, img_size, input_img_paths, target_img_paths)\n",
    "x.shape\n",
    "#x_train= np.reshape(20,3,img_size, input_img_paths, target_img_paths)(x)\n",
    "#y_train= np.reshape(20,3,img_size, input_img_paths, target_img_paths)(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from keras.activations import hard_sigmoid, relu\n",
    "from keras.layers import Conv2D, Concatenate, Reshape\n",
    "from keras.layers.convolutional import Conv2DTranspose\n",
    "from keras.layers import ConvLSTM2D\n",
    "from tensorflow.keras import layers\n",
    "from keras.layers import Layer\n",
    "#from keras.layers import BatchNormalization\n",
    "from numpy import reshape, true_divide\n",
    "import tensorflow as tf\n",
    "\n",
    "#encoder\n",
    "#convolutional- lstm layers\n",
    "\n",
    "#inp = layers.Input(shape=(None, *x_train.shape[2:]))\n",
    "inp = keras.Input(shape=(time_step,height,width,3),\n",
    "    batch_size=batch_size)\n",
    "\n",
    "print(inp.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class ReshapeLayer(Layer):\n",
    "    def call(self,inputs):\n",
    "        nshape = (batch_size,time_step) + inputs.shape[1:]\n",
    "        #print(f'nshape:{nshape.shape}')\n",
    "        return tf.reshape(inputs,nshape)\n",
    "\n",
    "def decon(filter, stride): \n",
    "    return Conv2DTranspose(filters=filter, kernel_size=(3,3), strides=(stride,stride),padding='same', activation= relu)\n",
    "\n",
    "def con(filter, stride):\n",
    "    return Conv2D(filters=filter, kernel_size=(3,3), strides= (stride,stride),padding= 'same')\n",
    "\n",
    "#input_image = Input(shape=(frames, channels, width, height))\n",
    "\n",
    "input_ = inp\n",
    "\n",
    "def depthnet(): \n",
    "\n",
    "    cnvlstm1= ConvLSTM2D(32, kernel_size=(7,7), strides=1, padding= 'same',  activation= relu,recurrent_activation=hard_sigmoid,return_sequences= True)(input_) #32\n",
    "    skip1 = tf.reshape (cnvlstm1,(-1,256,256,32))\n",
    "    #nm1=BatchNormalization(cnvlstm1)\n",
    "    #print(f'first shape: {cnvlstm1.shape}')\n",
    "    cnvlstm2= ConvLSTM2D(64, kernel_size=(5,5), strides=2, padding= 'same',  activation= relu,recurrent_activation=hard_sigmoid,return_sequences= True)(cnvlstm1) #64\n",
    "    #print(f'second shape: {cnvlstm2.shape}')\n",
    "    cnvlstm3= ConvLSTM2D(64, kernel_size=(5,5), strides=1, padding= 'same',  activation= relu,recurrent_activation=hard_sigmoid,return_sequences= True)(cnvlstm2) #64\n",
    "    #print(f'third shape: {cnvlstm3.shape}')\n",
    "    skip3 = tf.reshape (cnvlstm3,(-1,128,128,64))\n",
    "    #nm2=BatchNormalization(cnvlstm3)\n",
    "    cnvlstm4= ConvLSTM2D(128, kernel_size=(3,3), strides=2, padding= 'same',  activation= relu,recurrent_activation=hard_sigmoid,return_sequences= True)(cnvlstm3) #128\n",
    "    print(f'4ht shape: {cnvlstm4.shape}')\n",
    "    cnvlstm5= ConvLSTM2D(128, kernel_size=(3,3), strides=1, padding= 'same',  activation= relu,recurrent_activation=hard_sigmoid,return_sequences= True)(cnvlstm4) #128\n",
    "    print(f'5th shape: {cnvlstm5.shape}')\n",
    "    skip5 = tf.reshape (cnvlstm5,(-1,64,64,128))\n",
    "    #nm3=BatchNormalization(cnvlstm5)\n",
    "    cnvlstm6= ConvLSTM2D(256, kernel_size=(3,3), strides=2, padding= 'same',  activation= relu,recurrent_activation=hard_sigmoid,return_sequences= True)(cnvlstm5) #256\n",
    "    print(f'6th shape: {cnvlstm6.shape}')\n",
    "    skip6 = tf.reshape (cnvlstm6,(-1,32,32,256))\n",
    "    cnvlstm7= ConvLSTM2D(256, kernel_size=(3,3), strides=1, padding= 'same',  activation= relu,recurrent_activation=hard_sigmoid,return_sequences= True)(cnvlstm6)#256\n",
    "    print(f'7th shape: {cnvlstm7.shape}')\n",
    "    #nm4=BatchNormalization(cnvlstm7)\n",
    "    cnvlstm8= ConvLSTM2D(512, kernel_size=(3,3), strides=2, padding= 'same',  activation= relu,recurrent_activation=hard_sigmoid,return_sequences= True)(cnvlstm7)#512\n",
    "    print(f'8th shape: {cnvlstm8.shape}')\n",
    "    cnvlstm8= tf.reshape (cnvlstm8,(-1,16,16,512))\n",
    "    print(f'cnvlstm8 shape: {cnvlstm8.shape}')\n",
    "    #cnvlstm8=BatchNormalization(axis=1)(cnvlstm8)\n",
    "    #decoder \n",
    "    dec1=  decon(512,1)(cnvlstm8)\n",
    "    print(f'dec1 shape: {dec1.shape}')\n",
    "    \n",
    "    conc1= Concatenate()( [dec1 , cnvlstm8])\n",
    "    print(f'concat1 shape: {conc1.shape}')\n",
    "    conv1= con(512,1)(conc1)\n",
    "    #print(f'conv1 shape: {conv1.shape}')\n",
    "    #nm6= BatchNormalization(conv1)\n",
    "\n",
    "    dec2=  decon(256,2)(conv1)\n",
    "    dec2= decon(256,1)(dec2)\n",
    "    print(f'dec2 shape: {dec2.shape}')\n",
    "    conc2= Concatenate()( [dec2 , skip6])\n",
    "    conv2= con(256,1)(conc2)\n",
    "    print(f'conv2 shape: {conv2.shape}')\n",
    "    #nm7= BatchNormalization(conv2)\n",
    "\n",
    "    dec3=  decon(128,2)(conv2)\n",
    "    dec3=  decon(128,1)(dec3)\n",
    "    print(f'dec3 shape: {dec3.shape}')\n",
    "    conc3= Concatenate()( [dec3 , skip5])\n",
    "    conv3= con(128, 1)(conc3)\n",
    "    print(f'conv3: {conv3.shape}')\n",
    "    #nm6= BatchNormalization(conv3)\n",
    "\n",
    "    dec4=  decon(64,2)(conv3)\n",
    "    dec4=  decon(64,1)(dec4)\n",
    "    print(f'dec4: {dec4.shape}')\n",
    "    conc4= Concatenate()( [dec4 , skip3])\n",
    "    print(f'conc4: {conc4.shape}')\n",
    "    conv4= con(64, 1)(conc4)\n",
    "    print(f'conv4: {conv4.shape}')\n",
    "    #nm6= BatchNormalization(conv4)\n",
    "\n",
    "    dec5=  decon(32,2)(conv4)\n",
    "    dec5=  decon(32,1)(dec5)\n",
    "    print(f'dec5: {dec5.shape}')\n",
    "    conc5= Concatenate()( [dec5 , skip1])\n",
    "    print(f'conc5: {conc5.shape}')\n",
    "    conv5= con(32, 1)(conc5)\n",
    "    print(f'conv5: {conv5.shape}')\n",
    "    #conv5= BatchNormalization(conv5)\n",
    "    \n",
    "    dep = Conv2D(1, (1, 1), activation='sigmoid')(conv5)\n",
    "    print(f'dep: {dep.shape}')\n",
    "    out = ReshapeLayer()(dep)\n",
    "    #out = Reshape (-1,256,256,1) (dep)\n",
    "    print(f'out: {out.shape}')\n",
    "    net_model = keras.Model(inputs= [input_] , outputs= [out])\n",
    "    net_model.summary()\n",
    "    return net_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile\n",
    "from keras import metrics\n",
    "from keras import backend as K\n",
    "model = depthnet()\n",
    "\n",
    "def custom_loss_function(target, output):\n",
    "\n",
    "    first_log = K.log(K.clip(output, K.epsilon(), np.inf) + 1.)\n",
    "    second_log = K.log(K.clip(target, K.epsilon(), np.inf) + 1.)\n",
    "    print(f'log output: {first_log.shape}')\n",
    "    print(f'log target: {second_log.shape}')\n",
    "    loss= K.mean(K.square(first_log - second_log), axis=-1) - 0.5 * K.square(K.mean(first_log - second_log, axis=-1))\n",
    "    \n",
    "    #di = output - target\n",
    "    #di = tf.math.log(output) - tf.math.log(target)\n",
    "    #n = (64 * 64)\n",
    "    #di2 = tf.math.pow(di, 2)\n",
    "    #fisrt_term = tf.reduce_sum(di2)/n\n",
    "    #second_term = 0.5*tf.math.pow(tf.reduce_sum(di), 2)/ (n**2)\n",
    "    #loss = fisrt_term - second_term\n",
    "    return loss\n",
    "\n",
    "#model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "                  #loss=\"sparse_categorical_crossentropy\")\n",
    "                  \n",
    "model.compile(loss=custom_loss_function, optimizer=keras.optimizers.Adam(learning_rate=1e-4), metrics=[tf.keras.metrics.MeanSquaredLogarithmicError()])\n",
    "#model.compile(loss=keras.losses.BinaryCrossentropy, optimizer='adam', metrics=[metrics.RootMeanSquaredError, metrics.MeanSquaredLogarithmicError])\n",
    "epochs = 20\n",
    "#batch_size = 4\n",
    "\n",
    "# Fit the model to the training data.\n",
    "model.fit(x, y,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit ('3.10.5')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1a9dea948ae73b58193592b51458ad197351d0ffb642d250e04dd73824aacd7c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
