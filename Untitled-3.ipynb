{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roz/anaconda3/envs/NN/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from tensorflow.keras.activations import  relu, hard_sigmoid\n",
    "from tensorflow.keras.layers import  Conv2D, ConvLSTM2D, Conv2DTranspose\n",
    "from tensorflow.keras.layers import BatchNormalization , Concatenate\n",
    "from keras import Model\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR10Sequence(keras.utils.Sequence):\n",
    "\n",
    "    def __init__(self, x_set, y_set, batch_size):\n",
    "        self.x, self.y = x_set, y_set\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return math.ceil(len(self.x) / self.batch_size)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.x[idx * self.batch_size:(idx + 1) *\n",
    "        self.batch_size]\n",
    "        batch_y = self.y[idx * self.batch_size:(idx + 1) *\n",
    "        self.batch_size]\n",
    "\n",
    "        return np.array([\n",
    "            resize(imread(file_name), (200, 200))\n",
    "               for file_name in batch_x]), np.array(batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_generator = CIFAR10Sequence(partition['train'], labels, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from keras.activations import hard_sigmoid, relu\n",
    "# from keras.layers import Conv2D\n",
    "# from keras.layers.convolutional import Conv2DTranspose\n",
    "# from keras.layers import ConvLSTM2D\n",
    "# from keras.layers.normalization.BatchNormalization_v1 import BatchNormalization\n",
    "#encoder\n",
    "#convolutional- lstm layers\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def decon(filter): \n",
    "    return Conv2DTranspose(filters=filter, kernel_size=(3,3), strides= 1, padding= 'same', activation= relu)\n",
    "\n",
    "def con(filter, stride):\n",
    "    return Conv2D(filters=filter, kernel_size=(3,3), strides= (stride,stride))\n",
    "\n",
    "input_image = Input(shape=(frames, channels, width, height))\n",
    "input_ = input_image\n",
    "\n",
    "def depthnet(): \n",
    "\n",
    "    cnvlstm1= ConvLSTM2D(32, kernel_size=(7,7), strides=1, padding= 'same',  activation= relu,recurrent_activation=hard_sigmoid)(input_) #32\n",
    "    nm1=BatchNormalization(cnvlstm1)\n",
    "    cnvlstm2= ConvLSTM2D(64, kernel_size=(5,5), strides=2, padding= 'same',  activation= relu,recurrent_activation=hard_sigmoid)(nm1) #64\n",
    "    cnvlstm3= ConvLSTM2D(64, kernel_size=(5,5), strides=1, padding= 'same',  activation= relu,recurrent_activation=hard_sigmoid)(cnvlstm2) #64\n",
    "    nm2=BatchNormalization(cnvlstm3)\n",
    "    cnvlstm4= ConvLSTM2D(128, kernel_size=(3,3), strides=2, padding= 'same',  activation= relu,recurrent_activation=hard_sigmoid)(nm2) #128\n",
    "    cnvlstm5= ConvLSTM2D(128, kernel_size=(3,3), strides=1, padding= 'same',  activation= relu,recurrent_activation=hard_sigmoid)(cnvlstm4) #128\n",
    "    nm3=BatchNormalization(cnvlstm5)\n",
    "    cnvlstm6= ConvLSTM2D(256, kernel_size=(3,3), strides=2, padding= 'same',  activation= relu,recurrent_activation=hard_sigmoid)(nm3) #256\n",
    "    cnvlstm7= ConvLSTM2D(256, kernel_size=(3,3), strides=1, padding= 'same',  activation= relu,recurrent_activation=hard_sigmoid)(cnvlstm6)#256\n",
    "    nm4=BatchNormalization(cnvlstm7)\n",
    "    cnvlstm8= ConvLSTM2D(512, kernel_size=(3,3), strides=2, padding= 'same',  activation= relu,recurrent_activation=hard_sigmoid)(nm4)#512\n",
    "    nm5=BatchNormalization(cnvlstm8)\n",
    "    #decoder \n",
    "    dec1=  decon(512)(nm5)\n",
    "    conc1= Concatenate( [dec1 , nm5])\n",
    "    conv1= con(512, 2)\n",
    "    nm6= BatchNormalization(conv1)\n",
    "    dec2=  decon(256)(nm6)\n",
    "    conc2= Concatenate( [dec2 , nm4])\n",
    "    conv2= con(256, 1)\n",
    "    nm7= BatchNormalization(conv2)\n",
    "    dec3=  decon(128)(nm7)\n",
    "    conc3= Concatenate( [dec3 , nm3])\n",
    "    conv3= con(128, 2)\n",
    "    nm6= BatchNormalization(conv3)\n",
    "    dec4=  decon(64)(nm5)\n",
    "    conc4= Concatenate( [dec4 , nm2])\n",
    "    conv4= con(64, 1)\n",
    "    nm6= BatchNormalization(conv4)\n",
    "    dec5=  decon(32)(nm5)\n",
    "    conc5= Concatenate( [dec5 , nm1])\n",
    "    conv5= con(32, 2)\n",
    "    nm6= BatchNormalization(conv5)\n",
    "    dep = Conv2D(1, (1, 1), activation='sigmoid')(nm6)\n",
    "    net_model = Model(inputs= [input_image] , outputs= [d])\n",
    "    net_model.summary()\n",
    "    return net_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = depthnet()\n",
    "\n",
    "# loss function\n",
    "def custom_loss_function(output, target):\n",
    "    # di = output - target\n",
    "    di = target - output\n",
    "    n = (height * width)\n",
    "    di2 = np.power(di, 2)\n",
    "    fisrt_term = np.sum(di2,(1,2,3))/n\n",
    "    second_term = 0.5*np.power(np.sum(di,(1,2,3)), 2)/ (n**2)\n",
    "    loss = fisrt_term - second_term\n",
    "    return loss.mean()\n",
    "\n",
    "# Compile\n",
    "model.compile(optimizer=Adam(lr=1e-4), loss=custom_loss_function(model.outputs , gtruth))\n",
    "\n",
    "#train_loader = DataGenerator(\n",
    "    #data=df[:260].reset_index(drop=\"true\"), batch_size=BATCH_SIZE, dim=(HEIGHT, WIDTH))\n",
    "\n",
    "model.fit(train_loader,epochs=EPOCHS,validation_data=validation_loader,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('NN')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "626344daed0c42ae3048c35ad473a8619c79350fee44a24f4afbbc60690f3c8b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
